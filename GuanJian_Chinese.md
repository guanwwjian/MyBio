<html>
<link href="jianli.css"rel="stylesheet"></link>
</html>

关键/Jim Guan
---
- **求职意向**：大数据相关、算法相关
- **手机**：15624901008
- **邮箱**：guanwwjian@163.com

---

### 关于我
- 共3年工作经验
- 1年大数据工程师工作经验（数据中台）
- 2年大数据算法工程师工作经验（个性化推送相关）
- 善于学习新技术
- 认真负责

---

### 教育工作经历

|2019.4至今|App Annie|大数据工程师|
|:---|:---:|---:|
|2017.4 ~ 2019.3|搜狗公司|大数据算法工程师|
|2016.6 ~ 2016.12|SAP|Java开发实习生|
|2014.9 ~ 2017.4|北京理工大学|计算机科学与技术 硕士|
|2010.9 ~ 2014.7|同济大学|计算机科学与技术 本科|

---

### 职业技能

- 编程语言：
	- 掌握：**Python、Linux Shell**
	- 熟悉：**Java、Scala、SQL**
- IDE：能够使用**vim**及其他IDE
- 大数据处理：**Spark**（数据中台、个性化推送模型预测流程）、**Hadoop Streaming**（日志清洗）、**Hive**（数据统计）、**Celery**
- 机器学习：**TensorFlow**（Wide&Deep CTR预估模型）、**Spark ML**
- 测试：熟悉**Python Unit Test**的开发，了解**ETL的数据质量QA**
- 工作流程：**Scrum**
- AWS: **S3、Cognito、ElasticSearch Service、API Gateway**
- 数据库：**Redis、ElasticSearch、PostgreSQL、MySQL、SQLite**
- 容器：**Docker**
- 代码版本管理：熟悉基于**git**的多人协作工作模式
- **大学英语六级**
- 了解国内推送技术现状及部分细节

---

### 工作经历
#### App Annie 数据中台
##### 项目介绍
- App Annie 数据中台托管了公司的全部数据，在保证数据安全的前提下，为公司的各项产品提供了ETL、数据存储、数据分析等功能支持，定义了统一的数据格式，增强了数据的重用性；定义并实现了统一的开发框架，增强了代码的重用性，减少了架构安全性审核时间，提升了产品上线的迭代速度；对数据的读写接口做了封装，减少了技术迭代产生的成本
##### 担任角色
- Scrum开发小组成员
##### 参与工作
- Data Pipeline ETL框架模块
	- 是一个ETL框架，用户可以在该框架的基础上使用Pyspark完成ETL流程的开发
	- 定义了多个数据层，统一了数据的存储规范，抽取了ETL的共通逻辑，使用户通过PySpark建立ETL流程变得更简单
	- 在公司计算平台的基础上，实现了ETL流程对EC2集群的随启随用，用完即停
	- 针对Citus、ES等数据库建立了loader，使得将数据通过分布式的方式导入数据库更加简便快捷

- Data Pipeline Ingest API模块
	- 提供了一个Restful API接口, 数据发送方通过调用改接口可以向Data Pipeline提交数据或者数据的路径
	- 完全由AWS托管的服务构成（API Gateway、Lambda、Kinesis Data Firehose），服务稳定性由AWS保障，节省了MT导致的人力消耗
	- 使用IAM Role来进行鉴权，从而保证仅授权用户可以访问该接口

- Auto Pipeline SQL ETL框架模块
	- 是一个App Annie自研的ETL框架模块，ETL开发人员可以使用这个框架完成ETL的编写工作
	- 对Pyspark的Spark SQL做了封装，完善了与ETL相关的功能，使用户（ETL的开发人员）只需编写SQL就可以完成对ETL流程的开发，大大缩短了ETL开发时间
	- 是在Data Pipeline的基础上开发完成的

- Data Pipeline监控模块
	- 提供了一个带有UI的平台使用户可以方便的监控到所有的DataPipeline任务的运行状态
	- 使用AWS ELasticSearch Service中的ElasticSearch存储任务状态，Kibana作为UI供用户访问
	- 提供了基于IAM Role的鉴权机制，Kibana UI使用了基于Cognito的认证机制

- ETL流程的开发及日常维护
	- 参与了多个ETL流程的开发
	- ETL Task不稳定时对Task进行处理
	- 多次参与大规模的数据迁移

#### 搜狗 “今日十大热点” APP 个性化推送（Push）
##### 项目介绍：
- 今日十大热点是搜狗旗下的一款信息流APP，每日活跃用户50万，有效活跃用户数500万；推送（Push）是向手机发送通知栏消息，如果用户点击消息就可以引流至APP从而提升APP的活跃用户；个性化推送根据用户的历史行为对用户的兴趣建模，由模型选择用户感兴趣的内容发送推送消息，从而提升点击率
##### 担任角色：
- 独立负责技术侧的全部事宜
##### 参与工作：
- Pingback回执日志统计流程
	- 功能：根据配置，对“今日十大热点”pingback日志进行分钟级PV和天级UV统计，该流程支持按多个不同字段维度对日志进行筛选和分类
	- 使用编程语言：**Python、Shell、SQL**
	- 优势：
	    - 配置简单：配置文件中每种统计维度组合只需要一行配置项
	    - 配置项无需频繁修改：pingback日志中的已有字段新增字段值无需作出任何修改，新字段值的相关统计结果将自动列在统计表中
	    - 维护简单：当日志中出现新的字段，只需对hive视图作出修改，无需建新的Hive表
	- 架构：
	    - 使用**Hadoop Streaming**对数据进行清洗
	    - 使用**Hive**加载清洗好的数据
	    - 根据配置文件生成SQL语句并提交至Hive
	    - 将Hive的统计结果插入**Mysql**
	    - 使用**Redash**对Mysql中的统计结果进行可视化

- “今日十大热点”个性化推送CTR预估模型
	- 功能：计算用户-文章对的CTR预估评分，从而选出用户最可能点击的文章
	- 使用编程语言：**Python、Shell**
	- 使用基于**Tensorflow**构建的**Wide&Deep**模型
	- 使用**Spark**进行训练数据的分布式预处理，完成特征提取并将特征处理成**TFRecord**格式
	- 使用GPU训练模型，训练过程使用了动态学习率
	- 使用**Spark**加载**Tensorflow**模型实现分布式CTR评分预测流程，当Tensorflow模型结构发生变化时，无需修改预测流程代码
	- 根据pingback回执日志，进行ABtest实验以及相关的统计工作，根据ABtest的结果对模型进行调整

- “今日十大热点”个性化推送服务
	- 功能：收到推送指令后，为每一个用户选择目前CTR预估评分最高的文章，根据文章聚合用户，并把每一篇文章的推送用户集合提交至推送平台进行推送
	- 使用编程语言：**Python3**
	- 工作流程：为每个用户维护一个优先队列，接收CTR预估模型计算的文章评分，并将该文章评分插入到对应用户的优先队列中，评分最高的文章在队首。每当收到推送指令时，取出每个用户的队首文章，按文章聚合提交推送
	- 优先队列使用**Redis**的**Sorted Set**结构实现
	- Restful接口服务使用Python3下的**Sanic**框架
	- 为了保证推送速度，使用**Celery**框架提供的生产者-消费者模式来分布式获取每个用户的队首元素，使发送速度达到了100万用户/分钟
	- 对发送消息的模式及Payload进行调整，支持通知栏消息、锁屏通知等展现方式，以及多种不同的点击响应行为
	- 根据pingback回执日志，收集并更新客户端Pushid集合
	- 接入多个推送通道（友盟、极光、搜狗Push、华为、OPPO)，根据用户的机型选择不同的推送通道，从而提升推送消息的抵达率

#### 搜狗“搜狗搜索”APP 检索词个性化推荐及相关后端维护
##### 项目介绍：
- “搜狗搜索”是搜狗旗下的搜索APP，检索词个性化推荐就是在检索框附近根据用户历史行为展示一些用户可能检索的词语，从而提升用户使用体验
##### 担任角色：
- 负责个性化推荐算法以及个性化后端的更新和维护
##### 参与工作：
- 个性化后端的更新和维护
	- 使用编程语言：**C++**
	- 负责接收pingback记录用户搜索历史，以及根据搜索历史查询“搜索历史-推荐词”映照表，并把对应的推荐词返回给用户客户端
	- 搜索历史-推荐词映照表以及用户搜索历史存储在**Redis**当中
- 推荐算法的更新和维护
	- 使用编程语言：**Python、Shell**
	- 根据用户搜索pingback日志使用**协同过滤**算法计算“搜索历史-推荐词”映照表
	- 使用**AC自动机**算法配合运营黑名单进行黑名单模糊匹配
